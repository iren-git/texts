{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.base import ClassifierMixin, BaseEstimator\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считывание данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('SMSSpamCollection.txt', 'r') as f:\n",
    "    s = f.readline()\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Судя по всему, метки классов стоят в начале строки перед табуляцией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def isspam(label):\n",
    "    if label=='ham':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "with open('SMSSpamCollection.txt', 'r') as f:\n",
    "    labels = []\n",
    "    texts = []\n",
    "    for line in f:\n",
    "        mas = line.split('\\t')\n",
    "        labels.append(isspam(mas[0]))\n",
    "        texts.append('\\t'.join(mas[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\\n', 'Ok lar... Joking wif u oni...\\n', \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\\n\", 'U dun say so early hor... U c already then say...\\n', \"Nah I don't think he goes to usf, he lives around here though\\n\", \"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, \\xc2\\xa31.50 to rcv\\n\", 'Even my brother is not like to speak with me. They treat me like aids patent.\\n', \"As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\\n\", 'WINNER!! As a valued network customer you have been selected to receivea \\xc2\\xa3900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\\n', 'Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\\n']\n",
      "[0, 0, 1, 0, 0, 1, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(texts[:10])\n",
    "print(labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabulary = CountVectorizer().fit(texts)\n",
    "X_train = vocabulary.transform(texts)\n",
    "y_train = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1082)\t1\n",
      "  (0, 1316)\t1\n",
      "  (0, 1765)\t1\n",
      "  (0, 1767)\t1\n",
      "  (0, 2061)\t1\n",
      "  (0, 2338)\t1\n",
      "  (0, 3571)\t1\n",
      "  (0, 3615)\t1\n",
      "  (0, 3655)\t1\n",
      "  (0, 4114)\t1\n",
      "  (0, 4374)\t1\n",
      "  (0, 4501)\t1\n",
      "  (0, 5571)\t1\n",
      "  (0, 5958)\t1\n",
      "  (0, 7694)\t1\n",
      "  (0, 8084)\t1\n",
      "  (0, 8324)\t1\n",
      "  (0, 8548)\t1\n",
      "(5574, 8713)\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем скор логистической регрессии при кросс-валидации на трейне"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score is  0.933348526858\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "scores = cross_val_score(model, X_train, y_train, scoring='f1', cv=10)\n",
    "\n",
    "result = np.mean(scores)\n",
    "print 'Mean score is ', result "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим на нашем маленьком тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "\n",
    "with open('test.txt', 'r') as f:\n",
    "    test_texts = f.readlines()\n",
    "    \n",
    "X_test = vocabulary.transform(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 789)\t1\n",
      "  (0, 1828)\t1\n",
      "  (0, 2067)\t1\n",
      "  (0, 3380)\t1\n",
      "  (0, 3414)\t1\n",
      "  (0, 3972)\t1\n",
      "  (0, 5400)\t1\n",
      "  (0, 5453)\t1\n",
      "  (0, 5511)\t1\n",
      "  (0, 5849)\t1\n",
      "  (0, 6504)\t1\n",
      "  (0, 7545)\t1\n",
      "  (0, 7770)\t1\n",
      "  (0, 7806)\t2\n",
      "  (0, 7986)\t1\n",
      "  (0, 8124)\t1\n",
      "  (0, 8674)\t2\n"
     ]
    }
   ],
   "source": [
    "print(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(X_test)\n",
    "print result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Насколько я могу судить, ответы не совсем верные: как минимум 4 письмо - явный спам. Ну как-то не удалось. Общая картина верная"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем сразу функцию для подсчета скоров, чтобы не переписывать по 10 раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_range(trans, model):\n",
    "    for ngram_range in [(1, 1), (2, 2), (3, 3), (1, 3)]:\n",
    "        X_train = trans(ngram_range=ngram_range).fit_transform(texts)\n",
    "        print (\"%.3f\" % np.mean(cross_val_score(model, X_train, y_train, scoring='f1', cv=10))),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да, надо было 2 знака после запятой, но так удобнее сравнивать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.933 0.822 0.725 0.925\n"
     ]
    }
   ],
   "source": [
    "check_range(CountVectorizer, LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.927 0.645 0.379 0.888\n"
     ]
    }
   ],
   "source": [
    "check_range(CountVectorizer, MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.853 0.345 0.166 0.648\n"
     ]
    }
   ],
   "source": [
    "check_range(TfidfVectorizer, LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проанализируем различные методы. Скоры выводятся в порядке: униграммы, биграммы, триграммы, все вместе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer MultinomialNB \t0.927 0.645 0.379 0.888 None\n",
      "CountVectorizer Linear SVM \t0.938 0.855 0.759 0.930 None\n",
      "CountVectorizer LogisticRegression \t0.933 0.822 0.725 0.925 None\n",
      "CountVectorizer RandomForestClassifier \t0.881 0.843 0.743 0.837 None\n",
      "TfidfVectorizer MultinomialNB \t0.840 0.748 0.633 0.725 None\n",
      "TfidfVectorizer Linear SVM \t0.938 0.820 0.734 0.916 None\n",
      "TfidfVectorizer LogisticRegression \t0.853 0.345 0.166 0.648 None\n",
      "TfidfVectorizer RandomForestClassifier \t0.885 0.840 0.762 0.833 None\n"
     ]
    }
   ],
   "source": [
    "transes = {CountVectorizer: 'CountVectorizer', TfidfVectorizer: 'TfidfVectorizer'}\n",
    "models = {LogisticRegression(): 'LogisticRegression', MultinomialNB(): 'MultinomialNB', RandomForestClassifier():\n",
    "          'RandomForestClassifier', SVC(kernel='linear'): 'Linear SVM'}         \n",
    "\n",
    "for trans in transes.keys():\n",
    "    for model in models.keys():\n",
    "        print transes[trans], models[model], '\\t', check_range(trans, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы: Итак, из рассмотренных моделей Linear SVM работает лучше всех, хотя LogisticRegression не сильно отстает при применении CountVectorizer. Linear SVM спокойно отнеслась к Tf-idf - для униграмм ее скор вообще не изменился. \n",
    "\n",
    "Наивный Байес отлично отработал только с CountVectorizer на униграммах, почти во всех остальных местах его скор наименьший. Также видно, что он очень плохо работает с биграммами, и еще хуже с тиграммами, что ожидаемо - ему нужно как можно больше статистики, а по биграммам и триграммам ее намного меньше, чем по униграммам. \n",
    "\n",
    "Логистическая регрессия при применении CountVectorizer менее чувствительна к использованию n-грамм, чем Навный Байес. Также отмечу очень сильный спад логистической регрессии на n-граммах при росте n при применении Tfidf.\n",
    "\n",
    "Random Forest работает достаточно стабильно и вполне неплохо по сравнению с другими. Выбор векторизации на него почти не повлиял, да и колебания для различных n-грамм менее драматичны.\n",
    "\n",
    "Вообще заметно, что на всех моделях Tf-idf дает понижение скора. Это связано с тем, что при определении спама ключевыми являются как раз такие слова, которые часто встречаются (в этом же самом спаме как минимум). Tf-idf занижает значимость этих слов, что нам совсем не нужно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В общем, из рассмотренных моделей выбираю Linear SVM для униграмм, скор у нее стабильно выше вообще почти во всех комбинациях. Проверим, улучшилось ли что-то для нашего маленького теста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel='linear').fit(X_train, y_train)\n",
    "print(svm.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат такой же не идеальный."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы (продолжение): Tf-idf не самая удачная идея для выделения спама. n-граммы при n > 1 дают только ухудшение результата, что связано с недостатком статистики для моделей. Возможно, улучшение могут дать другие методы векторизации, отбор существенных признаков."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
